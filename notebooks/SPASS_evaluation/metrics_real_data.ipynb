{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from fusanet_utils.datasets.simulated import SimulatedPoliphonic\n",
    "from fusanet_utils.datasets.fusa import FUSA_dataset\n",
    "from fusanet_utils.transforms import Collate_and_transform\n",
    "\n",
    "scenarios = {0:'square', 1:'park', 2:'waterfront', 3:'market', 4:'street'}\n",
    "is_scenario = lambda filename: [key for key, scene in scenarios.items() if scene in filename][0]\n",
    "    \n",
    "preds_soft, labels, distances, places, names = [], [], [], [], []\n",
    "experiment_path = Path('../experiments/Poliphonic-PANN-sed-no-pretrained-valid-loss/')\n",
    "print(experiment_path)\n",
    "categories = json.load(open(str(experiment_path / 'index_to_name.json')))\n",
    "model = torch.load(str(experiment_path / 'model.pt'))\n",
    "model.eval()\n",
    "params = yaml.safe_load(open(str(experiment_path / 'params.yaml')))\n",
    "\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d781aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUMILAB_labeling(Dataset):\n",
    "    \n",
    "    def __init__(self, categories):\n",
    "        self.file_list, self.label_list = [], []\n",
    "        self.categories = categories\n",
    "        df = pd.read_csv('../datasets/AUMILAB/metadata/metadata1_4.txt', delim_whitespace=True)\n",
    "        print(df.columns)\n",
    "        for file_name, metadata in df.groupby('filename'):\n",
    "            file_path = Path('../datasets/AUMILAB/audios/') / file_name\n",
    "            if not file_path.exists():\n",
    "                print(file_path)\n",
    "                continue\n",
    "            self.file_list.append(file_path)\n",
    "            metadata = metadata[[\"class\", \"start\", \"end\"]]\n",
    "            metadata = metadata.rename(columns={\"end\":\"class\", \"start\": \"start (s)\", \"end\": \"end (s)\"})\n",
    "            self.label_list.append(metadata)\n",
    "            \n",
    "    def __getitem__(self, idx: int) -> Tuple[Path, pd.DataFrame]:\n",
    "        return (self.file_list[idx], self.label_list[idx])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9380e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AUMILAB_labeling(list(categories.values()))\n",
    "\n",
    "fusa_dataset = FUSA_dataset(ConcatDataset([dataset]), feature_params=params[\"features\"])\n",
    "fusa_loader = DataLoader(fusa_dataset, batch_size=10, shuffle=False, pin_memory=True, num_workers=2,\n",
    "                         collate_fn=Collate_and_transform(params[\"features\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b86b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_model, labels_model, file_names = [], [], []\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(fusa_loader):\n",
    "        preds_model.append(model(sample).numpy())\n",
    "        labels_model.append(sample['label'].numpy())\n",
    "        file_names.append(sample['filename'])\n",
    "preds_soft.append(np.concatenate(preds_model))\n",
    "labels.append(np.concatenate(labels_model))\n",
    "names.append(np.concatenate(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1a178",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "def plot_file_prediction(model: int, idx: int, th: float=None):\n",
    "    if th is not None:\n",
    "        pred = (preds_soft[model][idx] > th).T#[3:, :]\n",
    "    \n",
    "    label = labels[model][idx].T\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 6), facecolor='w', dpi=120,\n",
    "                           tight_layout=True, sharex=True, sharey=True)\n",
    "    ax[0].pcolormesh(label, cmap=plt.cm.Blues, vmin=0, vmax=1)\n",
    "    ax[1].pcolormesh(pred, cmap=plt.cm.Blues, vmin=0, vmax=1)\n",
    "    ax[0].set_title(names[model][idx])\n",
    "    ax[1].set_title('PredicciÃ³n')\n",
    "    cmap = ax[2].pcolormesh((pred - label), cmap=plt.cm.RdBu, vmin=-1, vmax=1)\n",
    "    fig.colorbar(cmap)\n",
    "    ax[2].set_title('Error')\n",
    "    ax[0].set_yticks(np.arange(0, len(dataset.categories), step=1) + 0.5)\n",
    "    ax[0].set_yticklabels((dataset.categories));\n",
    "    ax[0].grid()\n",
    "    ax[1].grid()\n",
    "    ax[2].grid()\n",
    "    \n",
    "    return Audio(Path('../datasets/AUMILAB/audios/') / names[model][idx])\n",
    "    \n",
    "plot_file_prediction(0, 1, 0.3)\n",
    "#plot_file_prediction(1, 90, 0.3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1b77823",
   "metadata": {},
   "source": [
    "th = 0.45\n",
    "models = ['Adavanne et al. 2017', 'Kong et al. 2019']\n",
    "preds = [preds_soft[model] > th for model in range(len(models))]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "176d3a3d",
   "metadata": {},
   "source": [
    "Por clase para todos los ambientes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d44aece3",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 6), facecolor='w', dpi=120,\n",
    "                       tight_layout=True, sharey=True, sharex=True)\n",
    "\n",
    "for k, model_name in enumerate(models):\n",
    "    insertions = np.mean((preds[k]==1) & (labels[k]==0), axis=(0, 1))\n",
    "    deletions = np.mean((preds[k]==0) & (labels[k]==1), axis=(0, 1))\n",
    "    error_rate = insertions + deletions\n",
    "    ax.barh(y=list(dataset.categories), width=100*error_rate, alpha=0.5, label=model_name)\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_xlabel('Error rate [%]');"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6c06bcd",
   "metadata": {},
   "source": [
    "Por ambiente separado por clase:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "933fe2fe",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(10,  6), facecolor='w', dpi=120,\n",
    "                       tight_layout=True, sharey=True, sharex=True)\n",
    "for k, model_name in enumerate(models):\n",
    "    insertions = np.mean(np.stack([(preds[k][places[k]==place] == 1) & (labels[k][places[k]==place] == 0) for place in scenarios.keys()]), axis=(1, 2))\n",
    "    deletions = np.mean(np.stack([(preds[k][places[k]==place] == 0) & (labels[k][places[k]==place] == 1) for place in scenarios.keys()]), axis=(1, 2))\n",
    "    \n",
    "    for ax_, ins, dels, scene in zip(ax, insertions, deletions, scenarios.values()):\n",
    "        error_rate = (ins + dels)*100\n",
    "        ax_.barh(y=list(dataset.categories), width=error_rate, label=model_name, alpha=0.5)\n",
    "        ax_.set_title(scene)\n",
    "        ax_.grid('on')\n",
    "        #ax_.legend()\n",
    "        ax_.set_xlabel('Error rate [%]')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a17a2d7",
   "metadata": {},
   "source": [
    "Por ambiente:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cedb927",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 3), facecolor='w', dpi=120,\n",
    "                       tight_layout=True, sharey=True, sharex=True)\n",
    "for k, model_name in enumerate(models):\n",
    "    insertions = np.mean(np.stack([(preds[k][places[k]==place] == 1) & (labels[k][places[k]==place] == 0) for place in scenarios.keys()]), axis=(1, 2, 3))\n",
    "    deletions = np.mean(np.stack([(preds[k][places[k]==place] == 0) & (labels[k][places[k]==place] == 1) for place in scenarios.keys()]), axis=(1, 2, 3))\n",
    "    error_rate = 100*(insertions+deletions)\n",
    "    ax.barh(y=list(scenarios.values()), width=error_rate, label=model_name, alpha=0.5)\n",
    "\n",
    "ax.legend(bbox_to_anchor=(0.3, 1.02, 1., .102))\n",
    "ax.grid()\n",
    "ax.set_xlabel('Error rate [%]');"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17eb7869",
   "metadata": {},
   "source": [
    "Por macro clase:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "209582ba",
   "metadata": {},
   "source": [
    "categories = {}\n",
    "for k, category in enumerate(dataset.categories):\n",
    "    categories[k] = category\n",
    "inv_categories = {}\n",
    "for key, values in categories.items():\n",
    "    inv_categories[values] = int(key)\n",
    "    \n",
    "macro_classes = ['human', 'animal', 'alerts', 'music', 'environmental', 'mechanical', 'vehicle']\n",
    "fusa_taxonomy = {0: ['crowd', 'shouting', 'talk', 'steps'],\n",
    "                 1: ['bird', 'dog'], \n",
    "                 2: ['siren', 'bells', 'alarm', 'horn', 'braking'],\n",
    "                 3: ['music'],\n",
    "                 4: ['rain', 'wind', 'water', 'river', 'waves'],\n",
    "                 5: ['cutting', 'drilling', 'fireworks', \n",
    "                     'impact', 'explosives', 'air_conditioner'],\n",
    "                 6: ['car_idling', 'car_moving', 'bus_idling', 'bus_moving', 'airborne',\n",
    "                     'motorcycle_idling', 'motorcycle_moving', 'truck_idling', 'truck_moving', 'Vwater']\n",
    "                }\n",
    "fusa_taxonomy_int = {}\n",
    "for key, values in fusa_taxonomy.items():\n",
    "    transformed_values = []\n",
    "    for value in values:\n",
    "        transformed_values.append(inv_categories[value])\n",
    "    fusa_taxonomy_int[key] = transformed_values\n",
    "        \n",
    "inv_taxonomy = {}\n",
    "for key, values in fusa_taxonomy_int.items():\n",
    "    for value in values:\n",
    "        inv_taxonomy[value] = key\n",
    "        \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3), facecolor='w', dpi=120,\n",
    "                       tight_layout=True, sharey=True, sharex=True)\n",
    "\n",
    "for k, model_name in enumerate(models):\n",
    "    pred_macro = np.stack([np.amax(preds[k][:, :, fusa_taxonomy_int[macro]], axis=-1) for macro in range(len(macro_classes))])\n",
    "    label_macro = np.stack([np.amax(labels[k][:, :, fusa_taxonomy_int[macro]], axis=-1) for macro in range(len(macro_classes))])\n",
    "\n",
    "    insertions = np.mean((pred_macro == 1) & (label_macro==0), axis=(1, 2))\n",
    "    deletions = np.mean((pred_macro == 0) & (label_macro==1), axis=(1, 2))\n",
    "\n",
    "    error_rate = 100*(insertions + deletions)\n",
    "    ax.barh(y=macro_classes, width=error_rate, label=model_name, alpha=0.5)\n",
    "ax.legend(bbox_to_anchor=(0.2, 1.02, 1., .102))\n",
    "ax.grid()\n",
    "ax.set_xlabel('Error Rate [%]');"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7343d9dd",
   "metadata": {},
   "source": [
    "Intercambio entre clase idling y clase moving:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c486b423",
   "metadata": {},
   "source": [
    "def count_swapped(class1, class2):\n",
    "    print(categories[str(class1)], categories[str(class2)])\n",
    "    swap1 = np.sum(((preds[:, class1, :] == 0) & (preds[:, class2, :] == 1) & (labels[:, class1, :] == 1) & (labels[:, class2, :] == 0) ))\n",
    "    swap2 = np.sum(((preds[:, class1, :] == 1) & (preds[:, class2, :] == 0) & (labels[:, class1, :] == 0) & (labels[:, class2, :] == 1) ))\n",
    "    print(swap1, swap2)\n",
    "\n",
    "\n",
    "count_swapped(7, 8)\n",
    "count_swapped(9, 10)\n",
    "count_swapped(18, 19)\n",
    "count_swapped(28, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3572f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusa-training",
   "language": "python",
   "name": "fusa-training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
