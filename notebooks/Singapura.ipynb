{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from fusanet_utils.datasets.external import get_label_transforms\n",
    "from fusanet_utils.datasets.simulated import SimulatedPoliphonic\n",
    "from fusanet_utils.datasets.fusa import FUSA_dataset\n",
    "from fusanet_utils.transforms import Collate_and_transform\n",
    "    \n",
    "preds_soft, labels, distances, places, names = [], [], [], [], []\n",
    "experiment_path = Path('../experiments/Poliphonic-PANN-sed-no-pretrained/')\n",
    "print(experiment_path)\n",
    "categories = json.load(open(str(experiment_path / 'index_to_name.json')))\n",
    "model = torch.load(str(experiment_path / 'model.pt'))\n",
    "model.eval()\n",
    "params = yaml.safe_load(open(str(experiment_path / 'params.yaml')))\n",
    "\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cd385",
   "metadata": {},
   "outputs": [],
   "source": [
    "singapura_classes = {\n",
    "    0: {0: 'Other', 1: 'Screeching', 2: 'Plastic crinkling', 3: 'Cleaning', 4: 'Gear'},\n",
    "    1: {0: 'Engine (other)', 1: 'Small engine', 2: 'Medium engine', 3: 'Large engine'},\n",
    "    2: {0: 'Machinery impact (other)', 1: 'Rock drill', 2: 'Jackhammer', 3: 'Hoe ram', 4: 'Pile driver'},\n",
    "    3: {0: 'Non-machinery impact (other)', 1: 'Glass breaking', 2: 'Car crash', 3: 'Explosion'},\n",
    "    4: {0: 'Powered saw (other)', 1: 'Chainsaw', 2: 'Small/medium rotating saw', 3: 'Large rotating saw'},\n",
    "    5: {0: 'Alert signal (other)', 1: 'Car horn', 2: 'Car alarm', 3: 'Siren', 4: 'Reverse beeper'},\n",
    "    6: {0: 'Music (other)', 1: 'Stationary music', 2: 'Mobile music'},\n",
    "    7: {0: 'Human voice (other)', 1: 'Talking', 2: 'Shouting', 3: 'Large crowd', 4: 'Amplified speech', 5: 'Singing'},\n",
    "    8: {0: 'Human movement (other)', 1: 'Footsteps', 2: 'Clapping'},\n",
    "    9: {0: 'Animal (other)', 1: 'Dog barking', 2: 'Bird chirping', 3: 'Insect chirping'},\n",
    "    10: {0: 'Water (other)', 1: 'Hose pump'},\n",
    "    11: {0: 'Weather (other)', 1: 'Rain', 2: 'Thunder', 3: 'Wind'},\n",
    "    12: {0: 'Brake (other)', 1: 'Friction brake', 2: 'Exhaust brake'},\n",
    "    13: {0: 'Train (other)', 1: 'Electric train'}\n",
    "}\n",
    "\n",
    "def translate_singapura_classes(singapura_class):\n",
    "    category = int(singapura_class.split('-')[0])\n",
    "    subcategory = int(singapura_class.split('-')[1])\n",
    "    if category == 13 and subcategory == 2:\n",
    "        subcategory = 0\n",
    "    return singapura_classes[category][subcategory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINGAPURA(Dataset):\n",
    "    \n",
    "    def __init__(self, categories):\n",
    "        repo_path = '../'\n",
    "        label_transforms = get_label_transforms(repo_path, \"Singapura\")\n",
    "        self.file_list, self.label_list = [], []\n",
    "        self.categories = categories\n",
    "        folder = Path('../datasets/SINGAPURA/labels_public')\n",
    "        for file_path in tqdm(list(folder.rglob('*.csv'))):\n",
    "            df = pd.read_csv(file_path)\n",
    "            for file_name, metadata in df.groupby('filename'):\n",
    "                folder = (file_name.split('][')[1]).split('T')[0]\n",
    "                file_path = Path('../datasets/SINGAPURA/labelled/') / folder / file_name\n",
    "                if not file_path.exists():\n",
    "                    print(file_path)\n",
    "                    continue\n",
    "                self.file_list.append(file_path)\n",
    "            metadata = metadata[[\"event_label\", \"proximity\", \"onset\", \"offset\"]]\n",
    "            metadata = metadata.rename(columns={\"event_label\":\"class\", \"onset\": \"start (s)\", \"offset\": \"end (s)\"})\n",
    "            metadata[\"class\"] = metadata[\"class\"].apply(lambda x: translate_singapura_classes(x))\n",
    "            label_exists = metadata[\"class\"].apply(lambda label: label in label_transforms)\n",
    "            labels = metadata[\"class\"].loc[label_exists].apply(lambda label: label_transforms[label])\n",
    "            metadata[\"class\"] = labels\n",
    "            self.label_list.append(metadata)\n",
    "            \n",
    "    def __getitem__(self, idx: int) -> Tuple[Path, pd.DataFrame]:\n",
    "        return (self.file_list[idx], self.label_list[idx])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SINGAPURA(list(categories.values()))\n",
    "\n",
    "fusa_dataset = FUSA_dataset(ConcatDataset([dataset]), feature_params=params[\"features\"])\n",
    "fusa_loader = DataLoader(fusa_dataset, batch_size=10, shuffle=False, pin_memory=True, num_workers=2,\n",
    "                         collate_fn=Collate_and_transform(params[\"features\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_model, labels_model, file_names = [], [], []\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(fusa_loader):\n",
    "        preds_model.append(model(sample).numpy())\n",
    "        labels_model.append(sample['label'].numpy())\n",
    "        file_names.append(sample['filename'])\n",
    "preds_soft.append(np.concatenate(preds_model))\n",
    "labels.append(np.concatenate(labels_model))\n",
    "names.append(np.concatenate(file_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusa-training",
   "language": "python",
   "name": "fusa-training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
